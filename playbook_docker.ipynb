{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "974e7af8-c400-41e0-a490-00eb8113373c",
   "metadata": {},
   "source": [
    "# Setting up the environment\n",
    "NVIDIA [TorchFort](https://github.com/NVIDIA/TorchFort) is a DL training and inference interface for HPC programs. This NVAITC playbook demonstrates how the perform online deep learning traning and inference in an HPC numerical simulation application.\n",
    "\n",
    "Let's start by cloning the TorchFort repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5df34d-6888-48cb-9c39-5f0b3227bc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/NVIDIA/TorchFort"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d7c2a5-ece9-43cd-afc6-bbb293f20a0b",
   "metadata": {},
   "source": [
    "They easiest way to setup TorchFort is by using the provided Dockerfile. The following command builds a Docker image, containing TorchFort, all its dependencies and NVHPC SDK (NVIDIA compilers, libraries and tools). Please note that whilst this example is using Docker, the same workflow applies to Apptainer (former Singularity) container with minor syntax differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db81576-5b67-4fa6-8f53-2d4e6438ff19",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd TorchFort\n",
    "#!docker build --no-cache --quiet -t torchfort:playbook .\n",
    "!docker build --quiet -t torchfort:playbook -f docker/Dockerfile .\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35cb0631-f307-4748-85b7-a8ffd92d0746",
   "metadata": {},
   "source": [
    "\n",
    "Next, we launch a container and bind mount the application source code which we wish to augment with online DL training and Inference capability. As an example application we use the open-source [CaNS](https://github.com/CaNS-World/CaNS) (Canonical Navier-Stokes) code. We will also bindmount the provided 'files' folder, which contains application source code/config modifications and case files, to streamline the example. So, let's first clone the CaNS code with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f68c919-9ded-4522-a776-c4039b3e2145",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone --recursive https://github.com/CaNS-World/CaNS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64eae241-2f48-471b-a076-90aa47b2388a",
   "metadata": {},
   "source": [
    "Subsequently, let's checkout to a state that's been verified to work with the current version of the playbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370d6aeb-d8fc-457f-b467-3ff97717a91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ./CaNS\n",
    "!git checkout de78afb6a62c2c0d785d07b7912216806dc1ade8\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821f2971-048c-4b80-bbd6-9bf9403aa429",
   "metadata": {},
   "source": [
    "Finally, let's launch the container with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4220a3-0f37-4bb5-9e10-e6d117445977",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker run \\\n",
    "-itd --gpus '\"device=0\"' -p 3355:3355 \\\n",
    "-v ./CaNS:/opt/CaNS \\\n",
    "-v ./files:/files/ \\\n",
    "--name torchfort_playbook_new \\\n",
    "torchfort:playbook /bin/bash/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb37b2e-6db6-49df-9121-65bb9a2121ee",
   "metadata": {},
   "source": [
    "Let's check that the container is running and extract its unique ID (to execute the following commands within the same container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94025e89-9175-4def-9dcf-55387d945cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker container ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc9f037-e88e-4902-a7cd-9b9de67b93e3",
   "metadata": {},
   "source": [
    "Let's also check that we have a GPU available within the container "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3a019d-e5e0-4985-83ff-56295b3d4deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker exec <id> nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fed5ba-feeb-4bab-8eb5-02a6e17d6698",
   "metadata": {},
   "source": [
    "# Online training with TorchFort\n",
    "\n",
    "As an example case we consider the prediction of wall-bounded turbulence from wall quantities using convolutional neural networks, as presented in ([Guastoni et al. 2020](https://iopscience.iop.org/article/10.1088/1742-6596/1522/1/012022)). In summary, we want to train a PyTorch Neural Network model which takes the wall shear stress field $\\mathbf{\\tau}(x,y,z,t)$ at the solid wall, $y=y_{wall}$ as an input and predicts the velocity field $\\mathbf{v}(x,y,z,t))$ at a certain height $y=y_{pred}$ as an output. \n",
    "\n",
    "To achieve this, we need to consider two aspects: 1. Model creation and 2. Application source code-changes to facilitate TorchFort library calls. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09456083-a3e2-42b0-a7fb-9fe4a63ccfdc",
   "metadata": {},
   "source": [
    "# Model Creation\n",
    "In the provided /scripts/fcn.py we have implemented a simple Convolutional Neural Network architecture. Let's create the model and save it onto disk as a torchscripted model by running the following cell. Please note that the number of input and output channel needs to be set according to the task. In this case both $\\mathbf{\\tau}$ and $\\mathbf{u}$ fields have three components so both channel dimensions are set as three. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1df4ad9-c3ae-4130-9a23-b43f7f1d3337",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker exec <id> python /files/python_model/fcn.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b045263-9893-46be-a6c3-795b6504d96b",
   "metadata": {},
   "source": [
    "# Application source-code changes\n",
    "\n",
    "There are numerous ways of formulating the online DL training/inference workflow and it will always be application specific. In this section, we detail the necessary building blocks. All of these application source code changes have been implemented for you in /files/CaNS_src_updates/. At the end, we simply just overwrite the original source code with the modified source code.\n",
    "\n",
    "\n",
    "1. Include TorchFort and CUDA Fortran.\n",
    "\n",
    "```\n",
    "  use torchfort\n",
    "  use cudafor\n",
    "```\n",
    "\n",
    "2. Declare and allocate necessary arrays e.g. \n",
    "\n",
    "```\n",
    "  real(rp), allocatable, dimension(:,:,:,:) :: input, output, label\n",
    "  ...\n",
    "  allocate( input(1:ng(1), 1:ng(2), 1:3, trainbs), &\n",
    "           output(1:ng(1), 1:ng(2), 1:3, trainbs), &\n",
    "            label(1:ng(1), 1:ng(2), 1:3, trainbs))\n",
    "```\n",
    "\n",
    "Please note, the example case uses OpenACC for GPU-acceleration. For multi-GPU runs, the simulation is performed using domain decomposition per MPI-process (in z-direction) but training/inference is performed using full $x-z$ planes which are gathered from each subdomain. \n",
    "\n",
    "3. Initialise a TorchFort model (or TorchFort distributed for multi-gpu training). Initialisation requires a name identifier for your model, a path to your config file, which specifies hyperparameters, the MPI_communicator for distributed_runs and the local rank of the process. Here you can inspect the example config file [config_fcn_torchscript.yaml](./pencil-code/samples/conv-slab/config_fcn_torchscript.yaml)\n",
    "```\n",
    "  if (nranks == 1) then\n",
    "    istat = torchfort_create_model(model_name, model_config_file, dev)\n",
    "  else\n",
    "    istat = torchfort_create_distributed_model(model_name, model_config_file, MPI_COMM_WORLD, dev)\n",
    "  endif\n",
    "  if (istat /= TORCHFORT_RESULT_SUCCESS) stop\n",
    "```\n",
    "\n",
    "4. If you wish to start training from an existing checkpoint we can do it as follows. Please note that each process reads the checkpoint, not just root.\n",
    "\n",
    "```\n",
    "  if (torchfort_load_ckpt) then\n",
    "    if (myid == 0) print*, \"Loading torchfort checkpoint\", torchfort_ckpt\n",
    "    istat = torchfort_load_checkpoint(model_name, torchfort_ckpt, isteptrain, istepval)\n",
    "    if (istat /= TORCHFORT_RESULT_SUCCESS) stop\n",
    "    if (myid == 0) print*, \"isteptrain\", isteptrain, \"istepval\", istepval\n",
    "  else\n",
    "    isteptrain = 0\n",
    "    istepval = 0\n",
    "  endif\n",
    "```\n",
    "\n",
    "The online DL training usually happens *within* the main simulation time/iteration loop and this is the case for the example. ALL of the following blocks of code are within this time loop scope. The time loop starts with the following line.\n",
    "```\n",
    "  do while(.not.is_done)\n",
    "```\n",
    "\n",
    "5. If we train, we must copy the local solution and label states to the buffers and distribute them, call the training method and optionally print out the loss value\n",
    "```\n",
    "    if (is_training .and. (timesample >= dtsample_scaled)) then\n",
    "       ...\n",
    "      !$acc kernels default(present)\n",
    "       ! copy inputs\n",
    "       input_local(1:n(1), 1:n(2), 1, sampleidx) = (tauxz(1:n(1),1:n(2),0) - txzmean(1)) / txzstd(1)\n",
    "       input_local(1:n(1), 1:n(2), 2, sampleidx) = (tauyz(1:n(1),1:n(2),0) - tyzmean(1)) / tyzstd(1)\n",
    "       input_local(1:n(1), 1:n(2), 3, sampleidx) = (tauzz(1:n(1),1:n(2),0) - tzzmean(1)) / tzzstd(1)\n",
    "       ! copy labels\n",
    "       label_local(1:n(1), 1:n(2), 1, sampleidx) = (u(1:n(1),1:n(2), kbot) - umean(kbot)) / ustd(kbot)\n",
    "       label_local(1:n(1), 1:n(2), 2, sampleidx) = (v(1:n(1),1:n(2), kbot) - vmean(kbot)) / vstd(kbot)\n",
    "       label_local(1:n(1), 1:n(2), 3, sampleidx) = (w(1:n(1),1:n(2), kbot) - wmean(kbot)) / wstd(kbot)\n",
    "       !$acc end kernels\n",
    "\n",
    "       if (mod(sampleidx, trainbs * nranks) == 0) then\n",
    "           sampleidx = 0\n",
    "           call distribute_batches(input_local, input, n, ng)\n",
    "           call distribute_batches(label_local, label, n, ng)\n",
    "\n",
    "           if (.not. is_validating) then\n",
    "             isteptrain = isteptrain + 1\n",
    "             !$acc host_data use_device(input, label)\n",
    "             istat = torchfort_train(model_name, input, label, loss_value)\n",
    "             !$acc end host_data\n",
    "             if (istat /= TORCHFORT_RESULT_SUCCESS) stop\n",
    "\n",
    "             if (myid == 0) print*, \"Training step\", isteptrain, \"training loss = \", loss_value\n",
    "\n",
    "```\n",
    "However, please note that the memory copying is only necessary due to the nature of the case. If we were to train a model that uses the global (or subdomain) solution state as an input we could directly pass it to the train method.\n",
    "\n",
    "6. If we perform inference, we follow the same structure of copying the local solution state, distributing the local states to form a global state and then performing the inference \n",
    "```\n",
    "       if (test_inference) then\n",
    "          !$acc kernels default(present)\n",
    "          input_local(1:n(1), 1:n(2), 1, sampleidx) = (tauxz(1:n(1),1:n(2),0) - txzmean(1)) / txzstd(1)\n",
    "          input_local(1:n(1), 1:n(2), 2, sampleidx) = (tauyz(1:n(1),1:n(2),0) - tyzmean(1)) / tyzstd(1)\n",
    "          input_local(1:n(1), 1:n(2), 3, sampleidx) = (tauzz(1:n(1),1:n(2),0) - tzzmean(1)) / tzzstd(1)\n",
    "          !$acc end kernels\n",
    "\n",
    "          if (mod(sampleidx, trainbs * nranks) == 0) then\n",
    "             sampleidx = 0\n",
    "             call distribute_batches(input_local, input, n, ng)\n",
    "\n",
    "             !$acc host_data use_device(input, output)\n",
    "             istat = torchfort_inference(model_name, input, output)\n",
    "             !$acc end host_data\n",
    "             if (istat /= TORCHFORT_RESULT_SUCCESS) stop\n",
    "```\n",
    "8. Checkpoints can be onto disk as follows. Please note that only the root rank will do the save.\n",
    "```\n",
    "       if (myid == 0) then\n",
    "         write(trainckptnum,'(i7.7)') isteptrain\n",
    "         filename = 'torchfort_checkpoint_'//trainckptnum\n",
    "         print \"(a20,i10,a12,a100)\", \"Writing checkpoint \", isteptrain, \" directory = \", filename\n",
    "         istat = torchfort_save_checkpoint(model_name, filename)\n",
    "         if (istat /= TORCHFORT_RESULT_SUCCESS) stop\n",
    "       endif\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d95e0ad-c15a-48a6-a39e-35d068aaa7f6",
   "metadata": {},
   "source": [
    "Please note that data-normalisation with the online training approach can be challenging. In this case we use\n",
    "\n",
    "$\\hat{x} = \\frac{x - \\langle x \\rangle}{\\langle (x - \\langle x \\rangle)^2 \\rangle}$\n",
    "\n",
    "where the mean and standard deviation have are acquired by pre-running (developing the flow from the initial conditions) the case without any training.\n",
    "\n",
    "Finally, let's copy the modified source code into CaNS with the following command. (Since the CaNS folder is bind-mounted to the running container we can copy the files outside of docker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d13ba5f-2073-4f06-af05-cbd41cf24e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp ./files/CaNS_src_updates/* ./CaNS/src/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de12cd3-8cdb-42e2-9705-9862b9d9bb30",
   "metadata": {},
   "source": [
    "# COMPILATION\n",
    "Code building process will of course vary between applications. Most of the times it is sufficient simply to include and link TorchFort with\n",
    "```\n",
    "-L$(TORCHFORT_ROOT)/lib -ltorchfort_fort -ltorchfort -L$(HDF5_ROOT)\n",
    "-I$(TORCHFORT_ROOT)/include -I$(HDF5_ROOT)\n",
    "```\n",
    "In this case, we provide slighly modified Makefiles and configs that replace those of the Original CaNS repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62278a8d-f5fd-4886-8634-83f8926ca4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp ./files/CaNS_config_updates/Makefile ./CaNS/Makefile\n",
    "!cp ./files/CaNS_config_updates/build.conf ./CaNS/build.conf\n",
    "!cp ./files/CaNS_config_updates/flags.mk ./CaNS/configs/flags.mk\n",
    "!cp ./files/CaNS_config_updates/external.mk ./CaNS/dependencies/external.mk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37af046-4557-43ac-bb46-1dd793dde699",
   "metadata": {},
   "source": [
    "Remember that the idea is to bring the application into the container where it can be easily compiled against pre-built TorchFort with the NVHPC SDK. Hence, the we execute compilation with docker commands as such"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec74a467-d8c9-4613-af31-d3e4843833da",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker exec <id> bash -c \"cd /opt/CaNS && make libs && make\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0166d993-12a5-44f7-8ced-b57fdbf0dafa",
   "metadata": {},
   "source": [
    "# Test case setup\n",
    "\n",
    "Now that the TorchFort-enabled CaNS code has been build, the last step is to run the test case. First, let's copy the previously generated CNN model to the case folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a31d025-a284-4fb9-b703-2c15b99a0731",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker exec <id> cp /files/python_model/cans_fcn.pt /files/reconstruction_case"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd42d83c-e09b-4390-bf15-49df4499d4a1",
   "metadata": {},
   "source": [
    "CaNS code will read runtime parameters from an input file 'input.nml' located in the case folder. This example comes with two CaNS input files: 1. input.stats.nml which is used to run the case up to 2000 time units without training to develop the flow and measure the normalisation statistics and 2. input.train.nml to start training from 2000 time units onwards. Let's first run the first part. Please note that we have to add the path to CaNS dependencies to LD_LIBRARY_PATH environment variable as they are not set in the container build."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb2f6bd-1cd8-41d4-8b16-8e33f5e94384",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker exec <id> cp /files/reconstruction_case/input.stats.nml /files/reconstruction_case/input.nml\n",
    "!docker exec <id> /bin/bash -c 'export LD_LIBRARY_PATH=/opt/CaNS/dependencies/cuDecomp/build/lib:${LD_LIBRARY_PATH} && \\\n",
    "                                        cd /files/reconstruction_case && \\\n",
    "                                        mpirun -np 1 --allow-run-as-root --bind-to none /opt/CaNS/run/cans'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e94b6b-12a1-495c-b458-c7bd061958e8",
   "metadata": {},
   "source": [
    "Now that we have a developed checkpoint (to exclude the initial transients) for the simulation and an estimate of the flow statistics for normalisation, we can start the training. We will overwrite the input.nml with it's training counterpart input.train.nml which specifies all necessary runtime parameters for traing e.g.\n",
    "```\n",
    "trainbs = 32\n",
    "nsamples_train = 3200\n",
    "nsamples_val = 320\n",
    "```\n",
    "which means that we will undertake nsamples_train/(trainbs * num_gpus) number of training steps, after which we will take nsamples_val/(trainbs * num_gpus) validation steps. Training checkpoints and inference results are save after each validation epoch. For the purposes of this demo the training step will proceed for a total of 500 steps. However, for best results the training should run considerably longer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c306f4-67c2-435a-988d-b2e716941051",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker exec <id> cp /files/reconstruction_case/input.train.nml /files/reconstruction_case/input.nml\n",
    "!docker exec <id> /bin/bash -c 'export LD_LIBRARY_PATH=/opt/CaNS/dependencies/cuDecomp/build/lib:${LD_LIBRARY_PATH} && \\\n",
    "                                        cd /files/reconstruction_case && \\\n",
    "                                        mpirun -np 1 --allow-run-as-root --bind-to none /opt/CaNS/run/cans'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33e94e0-e92e-4250-aad3-cae12c83a32a",
   "metadata": {},
   "source": [
    "# Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9943f02e-5d34-4a3b-acad-aa2447a4177b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = h5py.File(\"files/reconstruction_case/data/sample_0000500_0000.h5\", \"r\")\n",
    "print(list(data))\n",
    "print(data['label'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f25437-4b7f-4db5-a996-9e1052409343",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7, 10))\n",
    "for i, var in enumerate(['u', 'v', 'w']):\n",
    "    plt.subplot(3, 2, i*2 + 1)\n",
    "    plt.imshow(data[\"pred\"][0,i,:,:])\n",
    "    plt.colorbar()\n",
    "    plt.title(var)\n",
    "\n",
    "    plt.subplot(3, 2, i*2 + 2)\n",
    "    plt.imshow(data[\"label\"][0,i,:,:])\n",
    "    plt.colorbar()\n",
    "    plt.title(var)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
